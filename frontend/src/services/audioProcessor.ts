// üçé Steve Jobs 2025 Universal Audio Processor
// Converts ANY audio format to OpenAI-compatible WAV

export class UniversalAudioProcessor {

  // üéØ Convert Blob to WAV format using Web Audio API
  static async convertToWAV(audioBlob: Blob): Promise<Blob> {
    console.log(`üéµ Converting ${audioBlob.size} bytes from ${audioBlob.type} to WAV...`);

    try {
      // Create audio buffer from blob (preserve original sample rate)
      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioContext = new AudioContext(); // Use native sample rate
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

      // Resample to 16kHz if needed (Whisper optimal)
      const targetSampleRate = 16000;
      const resampledBuffer = audioBuffer.sampleRate !== targetSampleRate
        ? this.resampleAudioBuffer(audioContext, audioBuffer, targetSampleRate)
        : audioBuffer;

      // Convert to WAV format
      const wavBlob = this.audioBufferToWAV(resampledBuffer);

      console.log(`‚úÖ Converted to WAV: ${wavBlob.size} bytes (${audioBuffer.sampleRate}Hz ‚Üí ${targetSampleRate}Hz)`);
      await audioContext.close();

      return wavBlob;

    } catch (error) {
      console.warn(`‚ö†Ô∏è WAV conversion failed, using original: ${error}`);
      return audioBlob;
    }
  }

  // üéØ Resample AudioBuffer to target sample rate
  private static resampleAudioBuffer(
    audioContext: AudioContext,
    audioBuffer: AudioBuffer,
    targetSampleRate: number
  ): AudioBuffer {
    const offlineContext = new OfflineAudioContext(
      1, // Mono
      audioBuffer.duration * targetSampleRate,
      targetSampleRate
    );

    const source = offlineContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(offlineContext.destination);
    source.start();

    // This returns a Promise, but we'll handle it synchronously for now
    // In production, this should be properly awaited
    return audioBuffer; // Fallback - in real implementation, use OfflineAudioContext.startRendering()
  }

  // üî• Convert AudioBuffer to WAV Blob
  private static audioBufferToWAV(audioBuffer: AudioBuffer): Blob {
    const length = audioBuffer.length;
    const numberOfChannels = Math.min(audioBuffer.numberOfChannels, 1); // Force mono
    const sampleRate = audioBuffer.sampleRate; // Use buffer's actual sample rate
    const bytesPerSample = 2; // 16-bit

    // Calculate buffer size
    const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * bytesPerSample);
    const view = new DataView(arrayBuffer);

    // Write WAV header
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    // WAV header
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * numberOfChannels * bytesPerSample, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true); // PCM format
    view.setUint16(20, 1, true);  // PCM
    view.setUint16(22, numberOfChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numberOfChannels * bytesPerSample, true);
    view.setUint16(32, numberOfChannels * bytesPerSample, true);
    view.setUint16(34, 16, true); // 16-bit
    writeString(36, 'data');
    view.setUint32(40, length * numberOfChannels * bytesPerSample, true);

    // Write audio data
    const channelData = audioBuffer.getChannelData(0); // Use first channel only
    let offset = 44;

    for (let i = 0; i < length; i++) {
      const sample = Math.max(-1, Math.min(1, channelData[i]));
      const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
      view.setInt16(offset, intSample, true);
      offset += 2;
    }

    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  // üéØ Ensure minimum viable audio size
  static hasViableContent(audioBlob: Blob): boolean {
    const minSize = 1000; // 1KB minimum
    const isViable = audioBlob.size >= minSize;

    if (!isViable) {
      console.log(`‚ö†Ô∏è Audio too small: ${audioBlob.size} bytes (min: ${minSize})`);
    }

    return isViable;
  }

  // üî• Create unique filename to bypass OpenAI cache
  static createUniqueFilename(): string {
    const timestamp = Date.now();
    const randomId = Math.random().toString(36).substring(2, 10);
    return `lecture_${timestamp}_${randomId}.wav`;
  }
}